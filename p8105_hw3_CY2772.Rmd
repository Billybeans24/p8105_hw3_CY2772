---
title: "p8105_hw3_CY2772"
author: "Chenhui Yan"
date: "2024-10-13"
output: github_document
---
# Load Libraries and Set Plot Settings
```{r}
# Load necessary libraries
library(tidyverse)
library(ggplot2)
library(patchwork) # For combining plots
library(ggridges)
library(hexbin)     # For hexbin plots
library(lubridate)
library(p8105.datasets)

# Set global plot options
knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = .6,
  out.width = '90%'
)

options(
  ggplot2.continuous.color = 'viridis',
  ggplot2.continuous.fill = 'viridis'
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

# Problem 1
## Part a): Load and describe the Data:
```{r}
data("ny_noaa")
# View the dimensions of the dataset
dim(ny_noaa)
# View the structure of the dataset
str(ny_noaa)
# Summarize the dataset
summary(ny_noaa)
```
### A short description of the dataset:
* The ny_noaa dataset contains 2,595,176 observations and 7 variables.
* Variables:
  * id: Weather station identifier.
  * date: Date of the observation.
  * prcp: Precipitation (tenths of mm).
  * snow: Snowfall (mm).
  * snwd: Snow depth (mm).
  * tmax: Maximum temperature (tenths of degrees C).
  * tmin: Minimum temperature (tenths of degrees C).

### Missing Data:
```{r}
# Calculate missing data percentages
ny_noaa %>%
  summarise(
    prcp_missing = mean(is.na(prcp)) * 100,
    snow_missing = mean(is.na(snow)) * 100,
    snwd_missing = mean(is.na(snwd)) * 100,
    tmax_missing = mean(is.na(tmax)) * 100,
    tmin_missing = mean(is.na(tmin)) * 100
  )

```
* Observations:
  * Approximately 5.62% of prcp values are missing.
  * Approximately 14.68% of snow values are missing.
  * Approximately 22.80% of snwd values are missing.
  * A significant portion of tmax (43.69%) and tmin (46.23%) values are missing.

## Part b): Data cleaning
### Create Year, Month, and Day Variables
```{r}
# Create separate variables for year, month, and day
ny_noaa = ny_noaa %>%
  mutate(
    year = year(date),
    month = month(date),
    day = day(date)
  )
```
### Convert Units to Reasonable Measures
* Temperature: Convert from tenths of degrees Celsius to degrees Celsius.
* Precipitation: Convert from tenths of mm to mm.
```{r}
# Convert `prcp`, `tmax`, and `tmin` to numeric before changing units
ny_noaa = ny_noaa %>%
  mutate(
    prcp = as.numeric(prcp),
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin)
  )
# Adjust units for temperature and precipitation
ny_noaa = ny_noaa %>%
  mutate(
    prcp = prcp / 10,  # Precipitation in mm
    tmax = tmax / 10,  # Max temp in °C
    tmin = tmin / 10   # Min temp in °C
  )
```

### Identify Most Common Snowfall Values
```{r}
# Count the occurrences of each snowfall value
snow_counts = ny_noaa %>%
  count(snow) %>%
  arrange(desc(n))

# View the most common snowfall values
head(snow_counts)

```
* The most commonly observed value for snowfall is 0 mm, with 2,008,508 occurrences.
* This is expected as snowfall doesn't occur every day, especially outside the winter months.

## Part c) Visualization:
### Average Max Temperature in January and July Across Years
```{r}
##Prepare Data
# Filter data for January and July
jan_jul_temps = ny_noaa %>%
  filter(month %in% c(1, 7)) %>%
  group_by(id, year, month) %>%
  summarise(
    mean_tmax = mean(tmax, na.rm = TRUE),
    .groups = 'drop'
  ) %>%
  mutate(month = if_else(month == 1, "January", "July"))
##Create Plots
# Plot for January
p_jan = ggplot(jan_jul_temps %>% filter(month == "January"), 
                aes(x = year, y = mean_tmax, group = id, color = id)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Average Max Temperature in January",
    x = "Year",
    y = "Mean Max Temperature (°C)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Plot for July
p_jul <- ggplot(jan_jul_temps %>% filter(month == "July"), 
                aes(x = year, y = mean_tmax, group = id, color = id)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Average Max Temperature in July",
    x = "Year",
    y = "Mean Max Temperature (°C)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Combine plots using patchwork
(p_jan / p_jul) + plot_layout(heights = c(1, 1))

```

* Seasonal Patterns:

  * The January plot shows mean maximum temperatures below freezing for many stations. This is expected, as January is a winter month in New York.
  * The July plot shows mean maximum temperatures generally around 25°C to 30°C, which aligns with typical summer weather.
  
* Yearly Variation:
  
  * In both January and July, there is a regular seasonal cycle where temperatures seem consistent year-over-year, suggesting stability in average             seasonal temperatures over time.
  * However, in some years, the spread of the data seems more significant, indicating variations between different weather stations or some abnormal     weather patterns.
  
* Outliers:

  * January: There are a few points that appear significantly lower than others, especially in the 1980s, indicating some extremely cold values. These         could be legitimate observations or data errors.
  * July: There are some outliers around 15°C, which seem lower than the rest of the data points in the same period. These could be caused by errors in       data collection or unusual weather events.


## Part d) Visualization of tmax vs tmin Plot and Snowfall Distribution
### i. tmax vs tmin Plot
```{r}
# Hexbin plot for tmax vs tmin
p_temp = ggplot(ny_noaa, aes(x = tmin, y = tmax)) +
  geom_hex(bins = 50) +
  labs(
    title = "Relationship Between Minimum and Maximum Temperatures",
    x = "Minimum Temperature (°C)",
    y = "Maximum Temperature (°C)"
  ) +
  theme_minimal()

```
### ii. Snowfall Distribution by Year

```{r}
# Filter snowfall data
snowfall_filtered = ny_noaa %>%
  filter(snow > 0, snow < 100)
# Plot snowfall distribution by year using boxplots
p_snow = ggplot(snowfall_filtered, aes(x = factor(year), y = snow)) +
  geom_boxplot(outlier.size = 0.5, alpha = 0.7) +
  labs(
    title = "Distribution of Snowfall by Year",
    x = "Year",
    y = "Snowfall (mm)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    panel.grid.major.x = element_blank()
  )
# Combine the temperature and snowfall plots
p_temp + p_snow + plot_layout(ncol = 1)
```

# Problem 2
## Part a): Load, Tidy, and Organize the Data Sets
```{r}
##Load the Data
# Read in the demographic data
demographics = read.csv("./dataset_hw3/nhanes_covar.csv", skip = 4)

# Read in the accelerometer data
accelerometer = read.csv("./dataset_hw3/nhanes_accel.csv")

## Inspect the Data
# Inspect demographics data
str(demographics)
summary(demographics)

# Inspect accelerometer data
str(accelerometer)
summary(accelerometer)

##Exclude Participants Less Than 21 Years of Age and Those with Missing Demographic Data
# Exclude participants under 21
demographics = demographics %>%
  filter(age >= 21)

# Remove rows with missing demographic data
demographics = demographics %>%
  drop_na()

##Merge the Data Sets
# Merge datasets on SEQN
data = merge(accelerometer, demographics, by = "SEQN") %>% 
  pivot_longer(
    min1:min1440,
    names_to = "minute_interval",
    values_to = "MIMS"
  ) %>%
  mutate(
    sex = factor(sex, levels = c(1, 2), labels = c('male','female')),
    education = factor(education, levels = c(1, 2, 3), labels = c('Less than high school','High school equivalent','More than high school')),
    minute_interval = str_remove(minute_interval,'min')
    )
```
I merged the data and removed any observations where the age was less than 21 or where demographic data was missing. I converted the variables sex and education into factors, setting their levels to "male" and "female" for sex, and "Less than high school," "High school equivalent," and "More than high school" for education. Additionally, I removed the "min" strings from the minute_interval variable.

## Part b): Produce a Reader-Friendly Table
```{r}
# Prepare unique participant data
participant_data = data %>% 
  select(SEQN, sex, education) %>% 
  distinct()

# Create num_data
num_data = participant_data %>% 
  group_by(sex, education) %>% 
  summarise(number = n(), .groups = 'keep')

# Create readable data frame
readable_data = num_data %>% 
  pivot_wider(
    names_from = 'education',
    values_from = 'number'
  )

# Display the readable data
print(readable_data)

# Plot p1: Bar plot of counts
p1 = num_data %>% 
  ggplot(aes(x = education, y = number, fill = sex)) + 
  geom_col(position = position_dodge2(preserve = 'single')) +
  geom_text(aes(label = number), 
            position = position_dodge2(width = 0.9, preserve = 'single'), 
            vjust = -0.5, hjust = 0.5) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, vjust = 0.85, hjust = 0.75)) +
  labs(title = "Number of Participants by Sex and Education",
       x = "Education Level",
       y = "Number of Participants")

# Plot p2: Proportional bar plot
p2 = participant_data %>% 
  ggplot(aes(x = education, fill = sex)) +
  geom_bar(position = 'fill') +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, vjust = 0.85, hjust = 0.75)) +
  labs(title = "Proportion of Sex within Education Levels",
       x = "Education Level",
       y = "Proportion")

# Combine the plots
combined_plot = p1 + p2 + plot_layout(ncol = 2)
combined_plot
```
I began by creating a table that displays the number of men and women across different educational categories. To make the table more reader-friendly, I used the pivot_wider function to restructure it. The resulting plot shows that individuals with more than a high school education constitute the highest percentage among both men and women. Additionally, there are fewer men than women with less than a high school education, while more men than women have a high school equivalent education.

## Part c):Aggregate Total Activity
```{r}
## Aggregating Across Minutes for Each Participant
# Calculate total activity for each participant
total_activity_data = data %>%
  group_by(SEQN, sex, age, education) %>%
  summarise(total_activity = sum(MIMS, na.rm = TRUE), .groups = 'drop')

## Create a Plot of Total Activity vs. Age
# Create the plot
total_activity_plot = total_activity_data %>%
  ggplot(aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = 0.6) +  # Scatter plot points
  geom_smooth(method = "loess", se = FALSE) +  # Smooth trend lines
  facet_wrap(~ education) +  # Separate panels by education level
  labs(
    title = "Total Activity vs. Age by Sex and Education Level",
    x = "Age",
    y = "Total Activity (MIMS)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 30, vjust = 0.85, hjust = 0.75)
  )

# Display the plot
print(total_activity_plot)


```
In the graph, male data are displayed in red and female data in blue. Overall, women's total activity levels are higher than men's across all ages in the two graphs on the right. In the first graph on the left, women's total activity surpasses men's up to approximately age 40, after which it becomes lower than men's. Regarding overall trends, total activity decreases for individuals at all education levels after around age 60. Specifically, those with less than a high school education reach their highest total activity around age 20, while individuals with a high school equivalent education peak around age 40. People with more than a high school education maintain relatively high levels of total activity up until age 60.

## Part d):Making a three-panel plot
```{r}
##Create Plots
# Define a function to create the activity plot with improvements
create_activity_plot = function(education_level, title) {
  data %>%
    filter(education == education_level) %>%
    mutate(hourtime = floor(as.numeric(minute_interval) / 60)) %>%  # Use floor for grouping
    group_by(hourtime, sex) %>%  # Aggregate at hour level by sex
    summarise(mean_MIMS_per_hour = mean(MIMS, na.rm = TRUE), .groups = 'drop') %>%
    ggplot(aes(x = hourtime, y = mean_MIMS_per_hour, color = sex)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "loess", se = FALSE) +
    theme_minimal() +
    theme(legend.position = 'bottom') +
    labs(
      title = title,
      x = "Hour Interval",
      y = "Mean MIMS per Hour"
    )
}

# Create the improved plots
p1 = create_activity_plot('Less than high school', 'Less than High School')
p2 = create_activity_plot('High school equivalent', 'High School Equivalent')
p3 = create_activity_plot('More than high school', 'More than High School')

p1+p2+p3



```
The plot reveals distinct daily physical activity patterns across different education levels and between sexes. Generally, activity levels peak around midday for all education groups, reflecting common routines such as commuting, work-related movement, or exercise. Participants with higher education levels tend to exhibit more structured and higher overall activity throughout the day, indicating greater health awareness or access to physical activity opportunities. Women consistently show higher activity levels compared to men, especially in the "High School Equivalent" and "More than High School" groups, suggesting more engagement in structured activities or exercise. In contrast, participants with less than high school education exhibit lower peaks in activity, potentially indicating more sedentary behavior or fewer opportunities for physical activity. Across all groups, activity levels decline sharply during late evening hours, likely reflecting typical rest or sleep patterns. These observations highlight the need for targeted interventions to promote physical activity, particularly among those with lower education levels and during evening hours to reduce sedentary time.

# Problem 3
## Part a): Load, Tidy, and Organize the Data Sets
```{r}
# Load the data and merge the datasets together.
jan2020 = read_csv('./dataset_hw3/citibike/Jan 2020 Citi.csv')
jan2024 = read_csv('./dataset_hw3/citibike/Jan 2024 Citi.csv')
july2020 = read_csv('./dataset_hw3/citibike/July 2020 Citi.csv')
july2024 = read_csv('./dataset_hw3/citibike/July 2024 Citi.csv')
jan2020 = jan2020 %>% 
  mutate(month = "January", year = "2020")
jan2024 = jan2024 %>% 
  mutate(month = "January", year = "2024")
july2020 = july2020 %>% 
  mutate(month = "July", year = "2020")
july2024 = july2024 %>% 
  mutate(month = "July", year = "2024")
citi_bike_df = bind_rows(jan2020, july2020, jan2024, july2024)

# Check for missing values in key columns
citi_bike_df %>%
  select(member_casual, rideable_type, month, year) %>%
  summarise_all(~ sum(is.na(.)))

# Remove rows with missing rider type
citi_bike_df = citi_bike_df %>%
  filter(!is.na(member_casual), !is.na(rideable_type))



```
For each month's data, I added "month" and "year" as new columns and then merged them into a single dataset. The resulting combined dataset contains 99,485 observations and nine variables, including ride ID, rideable type, weekday, total duration, start station, destination, membership status (member or casual), month, and year. Additionally, I removed any rows with missing rider type information.

## part b): Create a Reader-Friendly Table of Total Rides by Year, Month, and Rider Type
```{r}
# Standardize rider type names
citi_bike_df = citi_bike_df %>%
  mutate(
    rider_type = case_when(
      tolower(member_casual) == "member" ~ "Member",
      tolower(member_casual) == "casual" ~ "Casual",
      TRUE ~ "Other"
    )
  )
# Function to aggregate ride counts
aggregate_rides = function(data, group_vars, new_name) {
  data %>%
    group_by(across(all_of(group_vars))) %>%
    summarise(!!new_name := n(), .groups = 'drop')
}

# Usage
ride_by_membership = aggregate_rides(citi_bike_df, c("member_casual", "year", "month"), "number_of_rides")

ride_by_membership
```
The reader-friendly table displays 8 rows and 4 variables: rider type (member or casual), year, month, and number of rides. The total number of casual riders for January 2020, July 2020, January 2024, and July 2024 are 984, 5,637, 2,108, and 10,894, respectively. In comparison, Citi Bike members rode a total of 11,436 in January 2020, 15,411 in July 2020, 16,753 in January 2024, and 36,262 in July 2024. Overall, the number of casual riders is consistently lower than that of Citi Bike members.

## part c): The 5 most popular starting stations for July 2024:
```{r}
the_5_popular_ss=citi_bike_df %>% 
  mutate(number=1) %>% 
  filter(month == 'July',year == 2024) %>% 
  group_by(start_station_name) %>% 
  summarise(total_start=sum(number), .groups='keep') %>% 
  arrange(desc(total_start)) %>% 
  head(5)
the_5_popular_ss
```
The 5 most popular starting stations are Pier 61 at Chelsea Piers with 163 rides, University Pl & E 14 St with 155 rides, W 21 St & 6 Ave with 152 rides, West St & Chambers St with 150 rides and W 31 St & 7 Ave with 146 rides.

## part d): Investigation Plot: Median Ride Duration by Weekday, Month, and Year
```{r}
# Calculate median ride duration grouped by weekdays, month, and year
median_duration_plot = citi_bike_df %>% 
  group_by(weekdays, month, year) %>% 
  summarise(
    median_duration = median(duration, na.rm = TRUE),
    .groups = 'drop'  # Ungroup after summarising
  ) %>% 
  # Ensure weekdays are ordered correctly
  mutate(
    weekdays = factor(weekdays, levels = c('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'), ordered = TRUE)
  ) %>% 
  # Create the plot
  ggplot(aes(x = weekdays, y = median_duration, colour = month, group = month)) +
    geom_line() +
    geom_point(size = 3) +
    theme_minimal() +
    theme(
      legend.position = 'bottom',
      axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
    facet_grid(. ~ year) +
    labs(
      title = "Effect of Weekday, Month, and Year on Median Ride Duration",
      x = "Weekday",
      y = "Median Ride Duration (minutes)",
      colour = "Month"
    )

# Display the investigation plot
print(median_duration_plot)
```
The plot illustrates that median durations in July are consistently longer than those in January for both years, indicating a seasonal trend. In July, the day with the highest median duration alternates between Saturday and Sunday. In contrast, January shows more stability, with slight increases in duration during weekends but generally lower durations than July across all weekdays. Additionally, overall median durations have decreased from 2020 to 2024.

## Part e): Distribution of Ride Duration for 2024
```{r}
# Filter data for the year 2024
distribution_2024 = citi_bike_df %>% 
  filter(year == 2024)

# Plot the distribution of ride duration
distribution_plot = distribution_2024 %>% 
  # Ensure categorical variables are factors with specified levels
  mutate(
    member_casual = factor(member_casual, levels = c('member', 'casual')),
    rideable_type = factor(rideable_type, levels = c('electric_bike','classic_bike'))
  ) %>% 
  ggplot(aes(x = duration, y = member_casual, fill = rideable_type)) +
    geom_density_ridges(scale = 0.9, alpha = 0.6, rel_min_height = 0.01) +
    theme_minimal() +
    facet_grid(. ~ month) +
    labs(
      title = "Distribution of Ride Duration in 2024",
      x = "Duration (minutes)",
      y = "Membership Type",
      fill = "Bike Type"
    ) +
    theme(
      legend.position = "bottom",
      axis.text.x = element_text(angle = 45, hjust = 1)
    )

# Display the distribution plot
print(distribution_plot)
```
The density plot illustrates the distribution of ride durations by membership status, month, and bike type. However, the distribution is skewed and unclear due to some exceptionally long durations. To provide a clearer view, I created an additional density plot excluding these outlier durations.

## Part f): Distribution of Ride Duration (Duration < 100 minutes) for 2024
```{r}
# Plot the distribution of ride duration for rides under 100 minutes
distribution_under_100 = distribution_2024 %>% 
  filter(duration < 100) %>% 
  # Ensure categorical variables are factors with specified levels
  mutate(
    member_casual = factor(member_casual, levels = c('member', 'casual')),
    rideable_type = factor(rideable_type, levels = c('electric_bike','classic_bike'))
  ) %>% 
  ggplot(aes(x = duration, y = member_casual, fill = rideable_type)) +
    geom_density_ridges(scale = 0.9, alpha = 0.6, rel_min_height = 0.01) +
    theme_minimal() +
    facet_grid(. ~ month) +
    labs(
      title = "Distribution of Ride Duration (< 100 minutes) in 2024",
      x = "Duration (minutes)",
      y = "Membership Type",
      fill = "Bike Type"
    ) +
    theme(
      legend.position = "bottom",
      axis.text.x = element_text(angle = 45, hjust = 1)
    )

# Display the distribution plot for duration < 100 minutes
print(distribution_under_100)
```
The plot reveals that Citi Bike members consistently engage in short-duration rides across both months, indicating regular and utilitarian use. In contrast, casual riders exhibit greater seasonal variability, particularly in July, with a higher proportion of longer-duration rides that suggest recreational or exploratory activities. For members, ride durations predominantly peak within the 0–15 minute range, with very few extended rides. While electric bikes are generally preferred for shorter trips, in July, casual riders are more likely to use them for longer journeys compared to classic bikes. Additionally, ride durations in January are shorter overall than in July, likely due to colder weather, which results in fewer or shorter rides, especially among casual riders.













